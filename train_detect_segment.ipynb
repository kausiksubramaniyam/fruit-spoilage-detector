{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9b8caa3522fc4cbab31e13b5dfc7808d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_574140e4c4bc48c9a171541a02cd0211",
              "IPY_MODEL_35e03ce5090346c9ae602891470fc555",
              "IPY_MODEL_c942c208e72d46568b476bb0f2d75496"
            ],
            "layout": "IPY_MODEL_65881db1db8a4e9c930fab9172d45143"
          }
        },
        "574140e4c4bc48c9a171541a02cd0211": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b913d755b34d638478e30705a2dde1",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0856bea36ec148b68522ff9c9eb258d8",
            "value": "100%"
          }
        },
        "35e03ce5090346c9ae602891470fc555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76879f6f2aa54637a7a07faeea2bd684",
            "max": 818322941,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ace3934ec6f4d36a1b3a9e086390926",
            "value": 818322941
          }
        },
        "c942c208e72d46568b476bb0f2d75496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6b7a2243e0c4beca714d99dceec23d6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5966ba6e6f114d8c9d8d1d6b1bd4f4c7",
            "value": " 780M/780M [02:19&lt;00:00, 6.24MB/s]"
          }
        },
        "65881db1db8a4e9c930fab9172d45143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60b913d755b34d638478e30705a2dde1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0856bea36ec148b68522ff9c9eb258d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "76879f6f2aa54637a7a07faeea2bd684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ace3934ec6f4d36a1b3a9e086390926": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d6b7a2243e0c4beca714d99dceec23d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5966ba6e6f114d8c9d8d1d6b1bd4f4c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone GitHub [repository](https://github.com/ultralytics/yolov5), install [dependencies](https://github.com/ultralytics/yolov5/blob/master/requirements.txt) and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "064b8a7a-a2c2-411f-edb6-e95deb3a8d8b"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "YOLOv5 ðŸš€ v7.0-10-g10c025d Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 22.6/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q ../gpl.zip -d ../"
      ],
      "metadata": {
        "id": "KT-QCOXbxq8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 1. Detect\n",
        "\n",
        "`detect.py` runs YOLOv5 inference on a variety of sources, downloading models automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases), and saving results to `runs/detect`. Example inference sources are:\n",
        "\n",
        "```shell\n",
        "python detect.py --source 0  # webcam\n",
        "                          img.jpg  # image \n",
        "                          vid.mp4  # video\n",
        "                          screen  # screenshot\n",
        "                          path/  # directory\n",
        "                          'path/*.jpg'  # glob\n",
        "                          'https://youtu.be/Zgi9g1ksQHc'  # YouTube\n",
        "                          'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "900ede7d-afb4-4e2c-ab53-7c8ceb5420a2"
      },
      "source": [
        "!python detect.py --weights runs/train/exp/weights/best.pt --img 640 --conf 0.5 --save-crop --source ../mb.jpg\n",
        "# display.Image(filename='runs/detect/exp/zidane.jpg', width=600)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp/weights/best.pt'], source=../mb.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.5, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-10-g10c025d Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/1 /content/mb.jpg: 384x640 18 mangos, 12.0ms\n",
            "Speed: 0.5ms pre-process, 12.0ms inference, 1.5ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp3\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --save-crop\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k18240bBog-A",
        "outputId": "8e1a903a-ed19-47b4-8ce3-bd3ca627aa1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=yolov5s.pt, source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=True, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v6.2-239-gf33718f Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "image 1/2 /content/yolov5/data/images/bus.jpg: 640x480 4 persons, 1 bus, 11.3ms\n",
            "image 2/2 /content/yolov5/data/images/zidane.jpg: 384x640 2 persons, 2 ties, 12.5ms\n",
            "Speed: 0.4ms pre-process, 11.9ms inference, 1.2ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp2\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkAzDWJ7cWTr"
      },
      "source": [
        "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
        "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/127574988-6a558aa1-d268-44b9-bf6b-62d4c605cc72.jpg\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Validate\n",
        "Validate a model's accuracy on the [COCO](https://cocodataset.org/#home) dataset's `val` or `test` splits. Models are downloaded automatically from the [latest YOLOv5 release](https://github.com/ultralytics/yolov5/releases). To show results by class use the `--verbose` flag."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQPtK1QYVaD_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "9b8caa3522fc4cbab31e13b5dfc7808d",
            "574140e4c4bc48c9a171541a02cd0211",
            "35e03ce5090346c9ae602891470fc555",
            "c942c208e72d46568b476bb0f2d75496",
            "65881db1db8a4e9c930fab9172d45143",
            "60b913d755b34d638478e30705a2dde1",
            "0856bea36ec148b68522ff9c9eb258d8",
            "76879f6f2aa54637a7a07faeea2bd684",
            "0ace3934ec6f4d36a1b3a9e086390926",
            "d6b7a2243e0c4beca714d99dceec23d6",
            "5966ba6e6f114d8c9d8d1d6b1bd4f4c7"
          ]
        },
        "outputId": "102dabed-bc31-42fe-9133-d9ce28a2c01e"
      },
      "source": [
        "# Download COCO val\n",
        "torch.hub.download_url_to_file('https://ultralytics.com/assets/coco2017val.zip', 'tmp.zip')  # download (780M - 5000 images)\n",
        "!unzip -q tmp.zip -d ../datasets && rm tmp.zip  # unzip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/780M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b8caa3522fc4cbab31e13b5dfc7808d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf60b1b-b098-4657-c863-584f4c9cf078"
      },
      "source": [
        "# Validate YOLOv5s on COCO val\n",
        "!python val.py --weights yolov5s.pt --data coco.yaml --img 640 --half"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/coco.yaml, weights=['yolov5s.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=True, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n",
            "YOLOv5 ðŸš€ v6.2-56-g30e674b Python-3.7.13 torch-1.12.1+cu113 CUDA:0 (Tesla V100-SXM2-16GB, 16160MiB)\n",
            "\n",
            "Fusing layers... \n",
            "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n",
            "100% 755k/755k [00:00<00:00, 52.7MB/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco/val2017' images and labels...4952 found, 48 missing, 0 empty, 0 corrupt: 100% 5000/5000 [00:00<00:00, 10509.20it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco/val2017.cache\n",
            "                 Class     Images  Instances          P          R     mAP@.5 mAP@.5:.95: 100% 157/157 [00:50<00:00,  3.10it/s]\n",
            "                   all       5000      36335       0.67      0.521      0.566      0.371\n",
            "Speed: 0.1ms pre-process, 1.0ms inference, 1.5ms NMS per image at shape (32, 3, 640, 640)\n",
            "\n",
            "Evaluating pycocotools mAP... saving runs/val/exp/yolov5s_predictions.json...\n",
            "loading annotations into memory...\n",
            "Done (t=0.81s)\n",
            "creating index...\n",
            "index created!\n",
            "Loading and preparing results...\n",
            "DONE (t=5.62s)\n",
            "creating index...\n",
            "index created!\n",
            "Running per image evaluation...\n",
            "Evaluate annotation type *bbox*\n",
            "DONE (t=77.03s).\n",
            "Accumulating evaluation results...\n",
            "DONE (t=14.63s).\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.374\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.572\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.402\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.211\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.423\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.311\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.516\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.566\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.378\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.625\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.724\n",
            "Results saved to \u001b[1mruns/val/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Select YOLOv5 ðŸš€ logger {run: 'auto'}\n",
        "logger = 'TensorBoard' #@param ['TensorBoard', 'Comet', 'ClearML']\n",
        "\n",
        "if logger == 'TensorBoard':\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir runs/train\n",
        "elif logger == 'Comet':\n",
        "  %pip install -q comet_ml\n",
        "  import comet_ml; comet_ml.init()\n",
        "elif logger == 'ClearML':\n",
        "  %pip install -q clearml && clearml-init"
      ],
      "metadata": {
        "id": "i3oKtE4g-aNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c44d1821-562d-4472-eeb5-26804ae47892"
      },
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python train.py --img 640 --batch 2 --epochs 60 --data data1.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=data1.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=60, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-10-g10c025d Python-3.7.15 torch-1.12.1+cu113 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5s.pt...\n",
            "100% 14.1M/14.1M [00:00<00:00, 148MB/s]\n",
            "\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gpl/train/labels... 91 images, 0 backgrounds, 0 corrupt: 100% 91/91 [00:00<00:00, 1586.01it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/gpl/train/labels.cache\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB ram): 100% 91/91 [00:00<00:00, 197.78it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gpl/valid/labels... 11 images, 0 backgrounds, 0 corrupt: 100% 11/11 [00:00<00:00, 668.39it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/gpl/valid/labels.cache\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 11/11 [00:00<00:00, 129.66it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m4.77 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp\u001b[0m\n",
            "Starting training for 60 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/59      0.51G     0.1126    0.06349          0          9        640: 100% 46/46 [00:07<00:00,  6.03it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:01<00:00,  1.78it/s]\n",
            "                   all         11         61     0.0449      0.311     0.0375    0.00885\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/59     0.715G    0.08936    0.07782          0         26        640: 100% 46/46 [00:04<00:00, 10.21it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  9.42it/s]\n",
            "                   all         11         61      0.327      0.607      0.337     0.0931\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/59     0.715G    0.08131    0.06637          0         10        640: 100% 46/46 [00:04<00:00, 10.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 13.52it/s]\n",
            "                   all         11         61      0.155      0.709      0.155     0.0476\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/59     0.715G    0.08161    0.05769          0         13        640: 100% 46/46 [00:04<00:00, 10.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 15.01it/s]\n",
            "                   all         11         61      0.134      0.689      0.165     0.0456\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/59     0.715G    0.07835    0.05506          0          7        640: 100% 46/46 [00:04<00:00, 10.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 15.94it/s]\n",
            "                   all         11         61      0.145      0.639      0.159     0.0485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/59     0.715G    0.07889    0.05383          0         16        640: 100% 46/46 [00:04<00:00, 10.43it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 17.03it/s]\n",
            "                   all         11         61       0.19      0.705       0.19     0.0492\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/59     0.715G    0.07418    0.05253          0         21        640: 100% 46/46 [00:04<00:00, 10.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.88it/s]\n",
            "                   all         11         61      0.489      0.787      0.602      0.202\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/59     0.715G    0.07188    0.04628          0          5        640: 100% 46/46 [00:04<00:00, 10.63it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.80it/s]\n",
            "                   all         11         61      0.374      0.862      0.402      0.144\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/59     0.715G    0.06939    0.04564          0         15        640: 100% 46/46 [00:04<00:00, 10.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.62it/s]\n",
            "                   all         11         61      0.683      0.607       0.67      0.196\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/59     0.715G    0.07184    0.04171          0          4        640: 100% 46/46 [00:04<00:00, 10.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.64it/s]\n",
            "                   all         11         61      0.436      0.705      0.557      0.181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/59     0.715G    0.06903    0.05119          0         24        640: 100% 46/46 [00:04<00:00, 10.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.65it/s]\n",
            "                   all         11         61      0.503      0.803      0.615      0.224\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/59     0.715G    0.06818    0.04363          0          2        640: 100% 46/46 [00:04<00:00, 10.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.45it/s]\n",
            "                   all         11         61      0.577       0.77      0.686      0.221\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/59     0.715G    0.07242    0.04342          0          2        640: 100% 46/46 [00:04<00:00, 10.62it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.76it/s]\n",
            "                   all         11         61      0.476      0.836      0.551      0.236\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/59     0.715G    0.06697    0.04024          0          8        640: 100% 46/46 [00:04<00:00, 10.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 20.18it/s]\n",
            "                   all         11         61      0.865      0.918      0.952      0.351\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/59     0.715G    0.06086    0.04632          0          4        640: 100% 46/46 [00:04<00:00, 10.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.96it/s]\n",
            "                   all         11         61      0.598      0.934      0.755      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/59     0.715G    0.05375    0.04541          0         13        640: 100% 46/46 [00:04<00:00, 10.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.33it/s]\n",
            "                   all         11         61      0.712      0.934      0.821      0.369\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/59     0.715G    0.05802    0.04507          0         21        640: 100% 46/46 [00:04<00:00, 10.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 20.04it/s]\n",
            "                   all         11         61       0.65      0.902      0.775      0.275\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/59     0.715G    0.05782    0.04259          0         17        640: 100% 46/46 [00:04<00:00, 10.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.51it/s]\n",
            "                   all         11         61      0.573      0.946      0.696      0.308\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/59     0.715G    0.04721    0.03766          0          0        640: 100% 46/46 [00:04<00:00, 10.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.43it/s]\n",
            "                   all         11         61      0.621      0.885      0.838       0.45\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/59     0.715G    0.04608    0.04057          0         11        640: 100% 46/46 [00:04<00:00, 10.55it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.07it/s]\n",
            "                   all         11         61      0.884      0.995      0.985      0.554\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/59     0.715G    0.04683     0.0421          0          8        640: 100% 46/46 [00:04<00:00, 10.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 17.88it/s]\n",
            "                   all         11         61      0.656      0.934      0.911      0.472\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/59     0.715G    0.04236    0.03996          0         10        640: 100% 46/46 [00:04<00:00, 10.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.71it/s]\n",
            "                   all         11         61      0.803          1      0.935      0.626\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/59     0.715G    0.03813    0.04369          0          5        640: 100% 46/46 [00:04<00:00, 10.15it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.86it/s]\n",
            "                   all         11         61      0.649      0.918       0.93      0.532\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/59     0.715G     0.0428    0.04059          0         10        640: 100% 46/46 [00:04<00:00, 10.52it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.23it/s]\n",
            "                   all         11         61      0.953          1      0.994      0.664\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/59     0.715G    0.03388    0.03751          0         24        640: 100% 46/46 [00:04<00:00, 10.22it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.78it/s]\n",
            "                   all         11         61      0.987          1      0.995      0.418\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/59     0.715G    0.04128     0.0389          0          7        640: 100% 46/46 [00:04<00:00, 10.36it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.31it/s]\n",
            "                   all         11         61      0.978          1      0.994      0.733\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/59     0.715G    0.03558    0.03634          0         12        640: 100% 46/46 [00:04<00:00, 10.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.77it/s]\n",
            "                   all         11         61      0.978          1      0.993      0.707\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/59     0.715G    0.03798    0.03248          0         24        640: 100% 46/46 [00:04<00:00, 10.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.20it/s]\n",
            "                   all         11         61       0.98          1      0.995      0.651\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/59     0.715G    0.03288     0.0367          0          4        640: 100% 46/46 [00:04<00:00, 10.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.98it/s]\n",
            "                   all         11         61      0.982          1      0.995      0.746\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/59     0.715G    0.03187    0.03612          0         10        640: 100% 46/46 [00:04<00:00, 10.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.84it/s]\n",
            "                   all         11         61      0.891          1      0.979       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      30/59     0.715G    0.03374    0.03805          0          8        640: 100% 46/46 [00:04<00:00, 10.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.66it/s]\n",
            "                   all         11         61      0.997          1      0.995      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      31/59     0.715G    0.03094    0.03654          0         10        640: 100% 46/46 [00:04<00:00, 10.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.46it/s]\n",
            "                   all         11         61      0.728      0.984      0.925      0.584\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      32/59     0.715G    0.03175    0.03599          0          8        640: 100% 46/46 [00:04<00:00, 10.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 20.12it/s]\n",
            "                   all         11         61       0.97          1      0.995      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      33/59     0.715G    0.02654    0.03513          0         17        640: 100% 46/46 [00:04<00:00, 10.19it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.78it/s]\n",
            "                   all         11         61      0.792      0.998      0.984      0.702\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      34/59     0.715G     0.0316    0.03616          0         14        640: 100% 46/46 [00:04<00:00, 10.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.96it/s]\n",
            "                   all         11         61      0.979          1      0.995      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      35/59     0.715G    0.02753    0.03575          0         10        640: 100% 46/46 [00:04<00:00, 10.29it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.28it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.789\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      36/59     0.715G    0.02747    0.03605          0         18        640: 100% 46/46 [00:05<00:00,  8.79it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.79it/s]\n",
            "                   all         11         61      0.999          1      0.995       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      37/59     0.715G    0.02589    0.03293          0          6        640: 100% 46/46 [00:04<00:00, 10.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 17.98it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.814\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      38/59     0.715G    0.02513    0.03654          0         16        640: 100% 46/46 [00:04<00:00, 10.31it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 17.22it/s]\n",
            "                   all         11         61      0.982          1      0.995      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      39/59     0.715G    0.02866    0.03317          0          8        640: 100% 46/46 [00:05<00:00,  8.59it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 17.54it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.845\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      40/59     0.715G    0.02404    0.03503          0         10        640: 100% 46/46 [00:04<00:00, 10.37it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.84it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.751\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      41/59     0.715G    0.02477    0.03605          0         13        640: 100% 46/46 [00:04<00:00, 10.38it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.46it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.818\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      42/59     0.715G    0.02347    0.03349          0          6        640: 100% 46/46 [00:04<00:00, 10.28it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.81it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.836\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      43/59     0.715G    0.02404    0.03113          0          5        640: 100% 46/46 [00:04<00:00, 10.48it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 20.15it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.785\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      44/59     0.715G    0.02294    0.03556          0          4        640: 100% 46/46 [00:04<00:00, 10.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.80it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.802\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      45/59     0.715G     0.0225    0.03051          0          8        640: 100% 46/46 [00:04<00:00, 10.30it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.74it/s]\n",
            "                   all         11         61      0.983          1      0.994      0.755\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      46/59     0.715G    0.02151    0.03179          0         16        640: 100% 46/46 [00:04<00:00, 10.45it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.01it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.846\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      47/59     0.715G     0.0198    0.03113          0          8        640: 100% 46/46 [00:04<00:00, 10.25it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.57it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.788\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      48/59     0.715G     0.0221    0.02799          0          2        640: 100% 46/46 [00:04<00:00, 10.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.23it/s]\n",
            "                   all         11         61      0.999          1      0.995       0.86\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      49/59     0.715G    0.01943     0.0274          0          2        640: 100% 46/46 [00:04<00:00, 10.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.42it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.836\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      50/59     0.715G    0.02083    0.03168          0         26        640: 100% 46/46 [00:04<00:00, 10.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.09it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.868\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      51/59     0.715G    0.01904    0.03118          0         17        640: 100% 46/46 [00:04<00:00, 10.44it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.53it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.865\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      52/59     0.715G    0.01866    0.02901          0         14        640: 100% 46/46 [00:04<00:00, 10.26it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 19.01it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.857\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      53/59     0.715G    0.01942    0.03119          0          4        640: 100% 46/46 [00:04<00:00, 10.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.82it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.875\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      54/59     0.715G    0.01759    0.03014          0         13        640: 100% 46/46 [00:04<00:00, 10.14it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 17.57it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.869\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      55/59     0.715G    0.01808    0.02613          0          8        640: 100% 46/46 [00:04<00:00, 10.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.98it/s]\n",
            "                   all         11         61      0.999          1      0.995       0.87\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      56/59     0.715G    0.01868      0.031          0         24        640: 100% 46/46 [00:04<00:00, 10.47it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 17.89it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.876\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      57/59     0.715G     0.0192    0.02977          0         26        640: 100% 46/46 [00:04<00:00, 10.34it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.88it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.871\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      58/59     0.715G    0.01819    0.02802          0          8        640: 100% 46/46 [00:04<00:00, 10.42it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.50it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.867\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      59/59     0.715G    0.01892    0.03059          0          6        640: 100% 46/46 [00:04<00:00, 10.39it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00, 18.71it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.874\n",
            "\n",
            "60 epochs completed in 0.085 hours.\n",
            "Optimizer stripped from runs/train/exp/weights/last.pt, 14.5MB\n",
            "Optimizer stripped from runs/train/exp/weights/best.pt, 14.5MB\n",
            "\n",
            "Validating runs/train/exp/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 3/3 [00:00<00:00,  5.40it/s]\n",
            "                   all         11         61      0.999          1      0.995      0.876\n",
            "Results saved to \u001b[1mruns/train/exp\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMusP4OAxFu6"
      },
      "source": [
        "# YOLOv5 PyTorch HUB Inference (DetectionModels only)\n",
        "import torch\n",
        "\n",
        "model = torch.hub.load('ultralytics/yolov5', 'yolov5s')  # yolov5n - yolov5x6 or custom\n",
        "im = 'https://ultralytics.com/images/zidane.jpg'  # file, Path, PIL.Image, OpenCV, nparray, list\n",
        "results = model(im)  # inference\n",
        "results.print()  # or .show(), .save(), .crop(), .pandas(), etc."
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}